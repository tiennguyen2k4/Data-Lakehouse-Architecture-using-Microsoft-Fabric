# Data Lakehouse Architecture for Enterprise Analytics using Microsoft Fabric

## Overview

This project implements a modern **Data Lakehouse Architecture** for enterprise analytics using **Microsoft Fabric**. It demonstrates best practices for building a scalable, maintainable data platform that integrates ERP data and delivers actionable business insights through multiple analytical layers.

## Architecture

The project follows the **medallion architecture** pattern with three distinct data layers:

### ðŸ¥‰ Bronze Layer (Raw Data)
- **Purpose**: Ingestion and raw data storage
- **Source**: ERP system (Supabase)
- **Processing**: Full load and incremental load pipelines
- **Content**: 30+ tables including:
  - Master data: Account, Address, BusinessEntity, Customer, Department, Employee, Location, Person, Product, Store, SalesTerritory
  - Transactional data: SalesOrderHeader, SalesOrderDetail, PurchaseOrderHeader, PurchaseOrderDetail, Transaction
  - Supporting tables: Class, EmailAddress, PersonPhone, ProductCategory, ProductDescription, ProductInventory, ProductModel, ProductSubCategory, ProductTransactionHistory

### ðŸ¥ˆ Silver Layer (Cleansed & Standardized)
- **Purpose**: Data quality, deduplication, and standardization
- **Processing**: Full load and incremental load transformation pipelines
- **Characteristics**: 
  - Cleaned and validated data
  - Standardized formats and naming conventions
  - Removed duplicates and handled null values
  - Optimized for analytics queries

### ðŸ¥‡ Gold Layer (Business-Ready Analytics)
- **Purpose**: Dimensional modeling and business analytics
- **Processing**: Full load and incremental load via SQL stored procedures
- **Characteristics**:
  - Star schema dimensional models
  - Fact and dimension tables
  - Optimized for reporting and BI tools
  - Pre-aggregated metrics where applicable

## Project Structure

```
â”œâ”€â”€ README.md                                    # This file
â”œâ”€â”€ Data Pipeline/                               # Orchestration pipelines
â”‚   â”œâ”€â”€ Bronze/
â”‚   â”‚   â”œâ”€â”€ Full load Source to Bronze/
â”‚   â”‚   â””â”€â”€ Incremental load Source to Bronze/
â”‚   â”œâ”€â”€ Silver/
â”‚   â”‚   â”œâ”€â”€ Full load Bronze to Silver/
â”‚   â”‚   â””â”€â”€ Incremental load Bronze to Silver/
â”‚   â”œâ”€â”€ Gold/
â”‚   â”‚   â”œâ”€â”€ Full load Silver to Gold/
â”‚   â”‚   â””â”€â”€ Incremental load Silver to Gold/
â”‚   â””â”€â”€ Manual Run Pipeline/
â”‚       â”œâ”€â”€ Customer Insight and Potential Report/
â”‚       â”œâ”€â”€ Finance Report/
â”‚       â””â”€â”€ Sales Report/
â”‚
â”œâ”€â”€ ETL/                                         # ETL notebooks and scripts
â”‚   â”œâ”€â”€ Bronze/
â”‚   â”‚   â”œâ”€â”€ ERP - Full Load/                    # 30+ full load notebooks
â”‚   â”‚   â”‚   â”œâ”€â”€ account - Full load.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ customer - Full load.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ product - Full load.ipynb
â”‚   â”‚   â”‚   â”œâ”€â”€ sales_order_header - Full load.ipynb
â”‚   â”‚   â”‚   â””â”€â”€ ... (25+ more tables)
â”‚   â”‚   â”œâ”€â”€ ERP - Incremental Load/             # Corresponding incremental notebooks
â”‚   â”‚   â””â”€â”€ Get Data From Supabase.ipynb        # Supabase connection utility
â”‚   â”œâ”€â”€ Silver/
â”‚   â”‚   â”œâ”€â”€ Full Load/
â”‚   â”‚   â”œâ”€â”€ Incremental Load/
â”‚   â”‚   â””â”€â”€ Init/
â”‚   â””â”€â”€ Gold/
â”‚       â”œâ”€â”€ Full Load/
â”‚       â”‚   â””â”€â”€ sp_fload_dim_account.sql        # Stored procedures for dimensions
â”‚       â”œâ”€â”€ Incremental Load/
â”‚       â””â”€â”€ Init/
â”‚
â””â”€â”€ Reports/                                     # Analytical reports
    â”œâ”€â”€ Customer Insight & Potential Report/
    â”œâ”€â”€ Finance Report/
    â””â”€â”€ Sales Report/
```

## Data Flow

### Full Load Process
```
Supabase (Source)
    â†“
Bronze Layer (Raw data ingestion)
    â†“
Silver Layer (Cleansing & standardization)
    â†“
Gold Layer (Dimensional modeling)
    â†“
Reports (Analytics & Business Intelligence)
```

### Incremental Load Process
```
Supabase (Updated records)
    â†“
Bronze Layer (Append/Update changed data)
    â†“
Silver Layer (Merge and standardize changes)
    â†“
Gold Layer (Update facts & dimensions)
    â†“
Reports (Updated analytics)
```

## Key Components

### ETL Notebooks

#### Bronze Layer
- **ERP - Full Load**: Initial data ingestion from Supabase for all 30+ tables
- **ERP - Incremental Load**: Delta processing for changed records
- **Get Data From Supabase.ipynb**: Reusable utility for connecting to Supabase

#### Silver Layer
- **Full Load**: Complete data transformation with quality checks
- **Incremental Load**: Efficient delta transformations

#### Gold Layer
- **SQL Stored Procedures**: Dimensional model creation and maintenance
- **Full Load**: Initial star schema population
- **Incremental Load**: Dimension and fact table updates

### Data Pipelines

- **Orchestration**: Manages end-to-end data flow from source to reports
- **Scheduling**: Supports both full and incremental refresh cycles
- **Manual Execution**: On-demand report generation for ad-hoc analysis

### Analytical Reports

1. **Customer Insight & Potential Report**
   - Customer segmentation and behavior analysis
   - Revenue and profitability metrics
   - Cross-sell and upsell opportunities

![Opportunity](Reports/Customer_Insight_and_Potential_Report/Opporunity.png)

![Survey](Reports/Customer_Insight_and_Potential_Report/Survey.png)


2. **Finance Report**
   - Revenue and expense tracking
   - Budget vs. actual analysis
   - Financial KPIs and trends

![Balance_Sheet](Reports/Finance_Report/Balance_Sheet.png)

![Cash_Flow](Reports/Finance_Report/Cash_Flow.png)

![Income_Statement](Reports/Finance_Report/Income_Statement.png)

3. **Sales Report**
   - Sales performance metrics
   - Territory and product analysis
   - Pipeline and forecast tracking

![Product_Inventory](Reports/Sales_Report/Product_Inventory_Dashboard.png)

![Sales](Reports/Sales_Report/Sales_Dashboard.png)

## Setup Instructions

### Prerequisites
- Microsoft Fabric workspace with appropriate permissions
- Supabase account with access to source ERP database
- Python 3.8+ for notebook execution
- SQL knowledge for stored procedure development

### Configuration

1. **Supabase Connection**
   - Update connection credentials in `Get Data From Supabase.ipynb`
   - Configure table names and schema details

2. **Fabric Workspace**
   - Create Bronze, Silver, and Gold lakehouses
   - Set up appropriate permissions and access controls
   - Configure compute resources for parallel processing

3. **Pipeline Setup**
   - Configure data pipeline trigger schedules
   - Set up monitoring and alerting
   - Test full load with sample data before production deployment

### Running the Project

#### Initial Full Load
```
1. Execute Bronze/ERP - Full Load notebooks (in sequence)
2. Execute Silver/Full Load notebooks
3. Execute Gold/Full Load stored procedures
4. Validate data quality and row counts at each layer
```

#### Incremental Load
```
1. Execute Bronze/ERP - Incremental Load notebooks
2. Execute Silver/Incremental Load notebooks
3. Execute Gold/Incremental Load stored procedures
4. Monitor for processing errors and data anomalies
```

#### Generate Reports
```
1. Use Data Pipeline/Manual Run Pipeline for on-demand reports
2. Or schedule automatic report generation via pipelines
3. Access reports through Power BI or Fabric reporting interface
```

## Best Practices

### Data Quality
- Implement validation checks at each layer
- Monitor data freshness and completeness
- Document data lineage and transformations
- Set up data profiling and quality metrics

### Performance
- Partition data by date ranges for large fact tables
- Index key columns in dimension tables
- Optimize SQL stored procedures for efficiency
- Monitor pipeline execution times and resource usage

### Maintenance
- Version control all notebooks and scripts
- Document schema changes and transformations
- Implement error handling and retry logic
- Schedule regular data archival and cleanup

### Security
- Encrypt sensitive data in motion and at rest
- Implement role-based access control (RBAC)
- Audit data access and modifications
- Follow organizational data governance policies

## Monitoring and Troubleshooting

### Common Issues

**Pipeline Failures**
- Check Supabase connectivity
- Verify table schema compatibility
- Review notebook logs for error details
- Validate data types and formats

**Data Quality Issues**
- Run data profiling and anomaly detection
- Compare row counts across layers
- Investigate unexpected null values
- Review business rule validations

**Performance Issues**
- Monitor compute resource utilization
- Analyze slow-running queries
- Consider data partitioning strategies
- Optimize transformations for efficiency

## Maintenance

### Regular Tasks
- Monitor pipeline execution and success rates
- Review data quality metrics
- Update documentation as needed
- Perform capacity planning reviews
- Test disaster recovery procedures

### Version Control
- Maintain version history of all notebooks and scripts
- Document changes in commit messages
- Use branches for development and testing
- Review code changes before production deployment

## Contributing

- Follow established naming conventions
- Test changes in development environment first
- Document new tables, fields, and transformations
- Ensure backward compatibility with existing pipelines
- Update this README with significant changes

## Support and Documentation

For more information about:
- **Microsoft Fabric**: [Microsoft Fabric Documentation](https://learn.microsoft.com/en-us/fabric/)
- **Data Lakehouse Architecture**: [Medallion Architecture Pattern](https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/data/medallion-architecture)
- **Supabase**: [Supabase Documentation](https://supabase.com/docs)


